{
  "hash": "ef8e9800a4a883ebe4f916ee135a5f50",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"PyTorch Basics: Dataset and DataLoader\"\ndescription: \"In this post we learn about how to download datasets with PyTorch Datasets, and how to retrieve data from them for training an ML model while keeping data and model separate. We will see that working with these classes is pretty easy, and allows us to use all kinds of handy built-in methods. \"\njupyter: python3\n---\n\n## Why seperate classes anyway?\n\nAccording to PyTorch:\n\n*\"Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity.\"*\n\nIn short, we try to prevent messy notebooks and [data leakage](https://www.ibm.com/think/topics/data-leakage-machine-learning#Causes+of+data+leakage) by seperating our data and data processing from our model. This is done with the `Dataset` and `DataLoader` classes.  \n\n\n## How to use the PyTorch Dataset class?\nWe will see that working with these classes is pretty easy.\nPyTorch has commonly datasets built-in, ready to work with. They are ordered by the task that they are used for, for example, since the fashionMNIST dataset is used for computer vision-related tasks, it is stored in the `torchvision` module. \n\nThe fashionMNIST dataset takes 4 parameters:\n\n- **root** is the folder name where the data will be stored in.\n\n- **train** specifies if you want to download the training or testing data.\n\n- **download** downloads the data from the internet when you don't have it locally yet.\n\n- **transform** takes a PIL image and transforms it to a tensor.\n\nLet's import the fashionMNIST dataset.\n\n::: {#fbeaa7c6 .cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show imports\"}\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n::: {#71eccd6c .cell execution_count=2}\n``` {.python .cell-code}\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor()\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor()\n)\n```\n:::\n\n\n## Dataset attributes\n\nNow that we saved the fashionMNIST dataset in a Dataset object, what can we do with it? \n\n::: {#selecting-img-label .cell execution_count=3}\n``` {.python .cell-code}\n# Dataset summary \ntraining_data\n\n# Class labels\ntraining_data.classes\n\n# Select a row of data\nimg, label = training_data[0]\n```\n:::\n\n\n<details>\n<summary>Show output</summary>\n\n::: {#849ad439 .cell execution_count=4}\n\n::: {.cell-output .cell-output-stdout}\n```\ntraining_data:\nDataset FashionMNIST\n    Number of datapoints: 60000\n    Root location: data\n    Split: Train\n    StandardTransform\nTransform: ToTensor() \n\ntraining_data.classes:\n[\n  'T-shirt/top',\n  'Trouser',\n  'Pullover',\n  'Dress',\n  'Coat',\n  'Sandal',\n  'Shirt',\n  'Sneaker',\n  'Bag',\n  'Ankle boot',\n] \n\nlabel:\n9\n```\n:::\n:::\n\n\n</details>\n\n:::{.callout-tip appearance=\"default\"}\nIt's always a good idea to inspect your data. Let's look at `img` and `label` from the first row of data.\n:::\n\n\n\n::: {#6dbc4dee .cell execution_count=6}\n``` {.python .cell-code}\nplt.imshow(img.squeeze(), cmap='gray')\nplt.set_title(training_data.classes[label])\n```\n:::\n\n\n::: {#f59f82ef .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=167 height=187}\n:::\n:::\n\n\n\n\nThat indeed looks like an ankle boot, very nice!\n\n## Using your own data with Dataset\nWe don't always want to use predefined datasets. Very often we have our own data that we want to use. Pytorch has two ways of creating your own dataset. the *map-style* dataset, which is most commonly used, and the *iterable-style* dataset, for data that comes in on the fly, such as user-log data. The map-style behaves as you would likely expect from a dataset: you know its length beforehand, and you can select data through an index. For this, map-style datasets need to implement the `__len__` and `__getitem__` method. Let's use our own data with a map-style Dataset\n\n\nConsider the case where we have a csv file of image file names and the labels associated with them.\n\n::: {#7ef4e982 .cell execution_count=9}\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item Name</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tshirt1.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tshirt2.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ankleboot999.jpg</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe would define a custom dataset class as such:\n\n::: {#b205b269 .cell execution_count=10}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\nfrom torchvision.io import read_image\n\nclass CustomImageDataSet(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform # optional\n        self.target_transform = target_transform # optional\n    \n    def __len__(self):\n        return len(self.img_labels)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n\n        img = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n\n        if self.transform:\n            img = self.transform(img)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return img, label\n\n```\n:::\n\n\nThe code above is a bit involved, so let's walk through it.\n\n- **\\_\\_init\\_\\_** stores values that we pass in variables, and reads the labels file `annotations_file`.\n\n- **\\_\\_len\\_\\_** specifies the size of the dataset by returning the amount of labels.\n\n**\\_\\_getitem\\_\\_** creates a path to an image. For example, if `img_dir='images'` and `idx=0`, then `img_path` is `images/tshirt1.jpg`. It then reads the image using a predefined PyTorch function, and reads the label. If any transformations are specified they are applied.\n\nWe can now select images and labels from our dataset, much like we did earlier in @selecting-img-label\n\n## How to use the PyTorch DataLoader class\n\nIn the code above we only specified how to return a single (image, label) pair. In practice, we typically use lots of images and labels (called batches) for per training step. Additionally, we want to shuffle data (to prevent overfitting) and we want to speed up the process using multiprocessing. This is where the DataLoader class steps in. Let's use the DataLoader to retrieve 64 images at once. \n\n::: {#66f93ef9 .cell execution_count=11}\n``` {.python .cell-code}\nfrom torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n\n# Get data for one simulated training step\ntrain_image_features, train_labels = next(iter(train_dataloader))\n```\n:::\n\n\nRemember that these images are the data used for one training step. Let's see the batch of images that our dataloader just sent us.\n\n::: {#51689271 .cell summary='Show visualization code' execution_count=12}\n``` {.python .cell-code code-fold=\"true\"}\nfigure = plt.figure(figsize=(8, 8))\ncols, rows = 8, 8\n\nfor i in range(cols * rows):\n    idx = i\n    img = train_image_features[idx]\n\n    figure.add_subplot(rows, cols, i +1)\n    plt.imshow(img.squeeze(), cmap=\"gray\")\n    plt.title(training_data.classes[train_labels[idx]], pad=1, fontsize=10)\n    plt.axis(\"off\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){width=618 height=624}\n:::\n:::\n\n\nThat's a lot of images! By using DataLoader, we have an easy way to retrieve lots of images from our data at once. \n\n## Different ways to shuffle \nWe can also control *how* data is shuffled (or in other words, the way that the random batch is sampled). We do this by setting the `sampler` parameter of the DataLoader. When doing this we have to set `shuffle=False`, since the shuffle parameter essentially sets the sampler parameter for us.\n\n::: {#85c842a4 .cell execution_count=13}\n``` {.python .cell-code}\nimport numpy as np\nfrom torch.utils.data.sampler import SequentialSampler, SubsetRandomSampler\n\n# Returns images in order.\n# The first batch will have the first 32 images, the second batch will have image 33-64, etc.\ntrain_loader = DataLoader(training_data, batch_size=32, sampler=SequentialSampler(training_data))\n\n# Sample randomly, only including the images 50-100.\nindices = np.arange(50, 101)\ntrain_loader = DataLoader(training_data, batch_size=32, sampler=SubsetRandomSampler(indices))\n```\n:::\n\n\nThese DataLoaders will select images in order of appearance in data, and randomly sample a subset of the data. Read about all the ways to sample in the [PyTorch documentation](https://docs.pytorch.org/docs/stable/data.html#data-loading-order-and-sampler).\n\n**To summarize:** With Dataset and DataLoader, PyTorch makes it easy to manage data efficiently and flexibly. In future posts, we’ll explore how these tools integrate into full training loops. \n\n## Further Reading\nPyTorch also offers ways to speed up sampling through multiprocessing and memory-pinning, which are both reasonably complicated and have some warnings attached to them, the latter being the reason that I did not include them in this post. If you are interested, or already know all about multiprocessing and GPU computations you can read about the topics [here](https://docs.pytorch.org/docs/stable/data.html#multi-process-data-loading). Thanks for reading all the way to the end, I hope to see you on day 3!\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}