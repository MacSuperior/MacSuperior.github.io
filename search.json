[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nDay 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX\n\n\n\n100 Days Of PyTorch\n\n\n\nDeploying your model might seem like a daunting task, and in some cases, it certainly is. But it is arguably one of the most import things to learn, since a model that never makes it out of your local machine is not useful to anybody. In this post we learn how to convert a trained model to the ONNX format, and deploy it permanently on HuggingFace for free with Gradio.\n\n\n\n\n\nMay 13, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 5: PyTorch Basics - Saving and Loading Models\n\n\n\n100 Days Of PyTorch\n\n\n\nPreviously, we learned how to train a neural network model. But how do we actually make predictions with it? And how can we use open-source models that other people trained? In this post we learn how to store and load the weights that the model learned during training, and how to use open-source models and weights\n\n\n\n\n\nMay 12, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 4 - PyTorch Basics: Building and Training a Neural Network\n\n\n\n100 Days Of PyTorch\n\n\n\nLearn how to use torch.nn to build the neural network structure, and how to train the model to recognize images, using a training and evaluation loop. It assumes you are already familiar with the theory behind neural networks (i.e loss functions, gradient descent).\n\n\n\n\n\nMay 11, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3: Pytorch Basics - Transforms\n\n\n\n100 Days Of PyTorch\n\n\n\n\n\n\n\n\n\nMay 10, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2: PyTorch Basics - Dataset and DataLoader\n\n\n\n100 Days Of PyTorch\n\n\n\nIn this post we learn about how to download datasets with PyTorch Datasets, and how to retrieve data from them for training an ML model while keeping data and model separate. We will see that working with these classes is pretty easy, and allows us to use all kinds of handy built-in methods.\n\n\n\n\n\nMay 9, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1: Pytorch Basics - Tensors\n\n\n\n100 Days Of PyTorch\n\n\n\nTensors lie at the heart of PyTorch. If we want to be proficient in PyTorch, we need to know what we can do with the Tensor object. There are over 1200 possible operations to perform on tensors, but only a few are needed to get started with PyTorch. In this post we learn what a Tensor is and how to perform basic operations with them. Familiarity with python programming is assumed.\n\n\n\n\n\nMay 8, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nBackpropagation: How Does Your Computer Calculate Gradients?\n\n\n\nexplanation\n\n\n\nHow backpropagation is used to compute gradients in neural networks, using computational graphs and the chain rule.\n\n\n\n\n\nApr 20, 2025\n\n\nLiam Groen\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I‚Äôm Liam Groen, a student from the Netherlands with a deep interest in machine learning, data science, and mathematics.\nI‚Äôm currently focused on building a strong foundation in ML by combining theory and practice:\nüìò Reading Pattern Recognition and Machine Learning by Bishop\nüß™ Working through PyTorch tutorials and hands-on experiments\nüéØ Committing to learn and build something new every day\nThis blog is where I document what I‚Äôm learning ‚Äî not only as a study aid, but as a way to share insights and connect with others on a similar journey.\n\n\n\n\nBuild solid understanding of machine learning fundamentals\nGet hands-on experience with real-world data and models\nPrepare for internships and a career in applied AI\n\n\n\n\n\nI‚Äôm always open to collaborating, learning together, or hearing from others in the field. Feel free to reach out on LinkedIn or check out my GitHub projects.\n\nVisualizing the optimization terrain of deep networks ‚Äî Li et al.¬†(2018)."
  },
  {
    "objectID": "about.html#my-learning-goals",
    "href": "about.html#my-learning-goals",
    "title": "About",
    "section": "",
    "text": "Build solid understanding of machine learning fundamentals\nGet hands-on experience with real-world data and models\nPrepare for internships and a career in applied AI"
  },
  {
    "objectID": "about.html#lets-connect",
    "href": "about.html#lets-connect",
    "title": "About",
    "section": "",
    "text": "I‚Äôm always open to collaborating, learning together, or hearing from others in the field. Feel free to reach out on LinkedIn or check out my GitHub projects.\n\nVisualizing the optimization terrain of deep networks ‚Äî Li et al.¬†(2018)."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html",
    "href": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html",
    "title": "Day 4 - PyTorch Basics: Building and Training a Neural Network",
    "section": "",
    "text": "Show imports\n\n\nimport os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n\nPyTorch allows us to create any neural network, using predefined building blocks from the module torch.nn. Every neural network we create should specify the forward method\n\nclass OurNeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Define neural net structure here, so we can store weights in them.\n        self.flatten = nn.Flatten()\n        self.linear_relu_chain = nn.Sequential(\n            nn.Linear(in_features=28*28, out_features=512),\n            nn.ReLU(),\n            nn.Linear(in_features=512, out_features=512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n    \n    def forward(self, input):\n        # Use neural net structure to pass input data through\n\n        input = self.flatten(input) # Shape: (28,28) -&gt; shape: (784)\n\n        predictions = self.linear_relu_chain(input) # Shape: (784) -&gt; shape: (512) -&gt; shape: (512) -&gt; shape: (10)\n        \n        return predictions\n\nLets instantiate it. In PyTorch, we also have to specify it on what device type we want to train our model. This allows for quicker training, depending on device type.\n\nmodel = OurNeuralNetwork().to(\"cpu\") # or cuda, mps, mtia, xpu\nprint(\"using cpu\")\n\nusing cpu\n\n\n\nmodel\n\nOurNeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_chain): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html#defining-the-network",
    "href": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html#defining-the-network",
    "title": "Day 4 - PyTorch Basics: Building and Training a Neural Network",
    "section": "",
    "text": "Show imports\n\n\nimport os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n\nPyTorch allows us to create any neural network, using predefined building blocks from the module torch.nn. Every neural network we create should specify the forward method\n\nclass OurNeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Define neural net structure here, so we can store weights in them.\n        self.flatten = nn.Flatten()\n        self.linear_relu_chain = nn.Sequential(\n            nn.Linear(in_features=28*28, out_features=512),\n            nn.ReLU(),\n            nn.Linear(in_features=512, out_features=512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n    \n    def forward(self, input):\n        # Use neural net structure to pass input data through\n\n        input = self.flatten(input) # Shape: (28,28) -&gt; shape: (784)\n\n        predictions = self.linear_relu_chain(input) # Shape: (784) -&gt; shape: (512) -&gt; shape: (512) -&gt; shape: (10)\n        \n        return predictions\n\nLets instantiate it. In PyTorch, we also have to specify it on what device type we want to train our model. This allows for quicker training, depending on device type.\n\nmodel = OurNeuralNetwork().to(\"cpu\") # or cuda, mps, mtia, xpu\nprint(\"using cpu\")\n\nusing cpu\n\n\n\nmodel\n\nOurNeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_chain): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html#testing-the-network",
    "href": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html#testing-the-network",
    "title": "Day 4 - PyTorch Basics: Building and Training a Neural Network",
    "section": "Testing the Network",
    "text": "Testing the Network\nLets simulate an 28x28 pixel image with some random numbers\n\nshape = (1, 28, 28)\nfake_image = torch.rand(shape, device=\"cpu\") # the tensor needs to be on the same device as the model\n\n\n\nShow plotting code\nimport matplotlib.pyplot as plt\n\nplt.imshow(fake_image.squeeze())\nplt.axis(\"off\")\nplt.title(\"Fake number - random 28x28 tensor\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nmodel_outputs = model(fake_image)\n\nEven though we specified nn.Linear(in_features=28*28), we set shape = (1, 28, 28) and not to (28, 28). This is because the model expects the first number to be the amount of images we use per batch of training. Since we are not actually training the model right now we set it to 1.\n\nprobabilities = nn.Softmax(dim=1)(model_outputs)\npredicted_label = probabilities.argmax(1)\npredicted_label.item()\n\n3\n\n\nOf course, the output is completely random, since the network was not trained and since the image was not actually a number."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html#training-and-evaluating-the-network",
    "href": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html#training-and-evaluating-the-network",
    "title": "Day 4 - PyTorch Basics: Building and Training a Neural Network",
    "section": "Training and Evaluating the Network",
    "text": "Training and Evaluating the Network\nLet‚Äôs train the network on the FashionMNIST dataset to classify images. For this we import the dataset using the code from a previous post explaining PyTorch Datasets and DataLoaders\n\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=transforms.ToTensor()\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=transforms.ToTensor()\n)\n\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n\nWe need to specify 3 parameters:\n\nNumber of Epochs - How many times to iterate over the entire dataset.\nLearning Rate - A scaling factor specifying how much to update the model parameters each iteration\nBatch Size - How much examples to iterate over before updating parameters.\n\nPer batch of images, model parameters are updated, until all images in the dataset have been seen. This process is repeated for the specified number of epochs.\n\nlearning_rate = 1e-3\nbatch_size = 64\nepochs = 5\n\nIn each epoch we also want to check the model performance (to see if it is improving). That is why we will build two loops.\n\nTraining Loop - Update parameters by showing model images with labels (from train_dataloader)\nChecking Loop - Evaluate model performance with learned parameters from the training loop on new images (from test_dataloader)\n\n\ndef train_loop(dataloader, model, loss_func, optimizer):\n    size = len(dataloader.dataset)\n    model.train() # Set model to training mode\n\n    # Update parameters each new batch\n    for batch, (images, labels) in enumerate(dataloader):\n        model_predictions = model(images)\n        loss = loss_func(model_predictions, labels)\n\n        # Compute gradient with backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        # Something to look at while model trains\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * batch_size + len(images)\n            print(f\"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]\")\n\n\ndef checking_loop(dataloader, model, loss_func):\n    size = len(dataloader.dataset)\n    number_of_batches = len(dataloader)\n    test_loss, correct_amount = 0, 0\n\n    model.eval() # Set model to check/test mode\n\n    with torch.no_grad(): # We don't need to update parameters anymore. This speeds up testing.\n\n        # This dataloader contains the test images\n        for images, labels in dataloader:\n            model_predictions = model(images)\n            \n            loss = loss_func(model_predictions, labels).item()\n            test_loss += loss\n\n            predicted_labels = nn.Softmax(dim=1)(model_predictions).argmax(1)\n            correct = predicted_labels == labels\n            # Turn every 'True' into a 1, and sum over them, converting the resulting tensor to a python integer\n            correct_amount += correct.type(torch.float).sum().item()\n\n    test_loss /= number_of_batches\n    correct_amount /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct_amount):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n\")\n\nLets train our model, passing a loss function and optimizer.\n\nloss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n\n# Train the model\nepochs = 10\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loop(train_dataloader, model, loss_function, optimizer)\n    checking_loop(test_dataloader, model, loss_function)\nprint(\"Done!\")\n\n\n\nShow output\n\n\n\n\nEpoch 1\n-------------------------------\nloss: 1.469673  [   64/60000]\nloss: 1.433510  [ 6464/60000]\nloss: 1.416146  [12864/60000]\nloss: 1.377274  [19264/60000]\nloss: 1.353796  [25664/60000]\nloss: 1.429164  [32064/60000]\nloss: 1.270087  [38464/60000]\nloss: 1.251621  [44864/60000]\nloss: 1.361366  [51264/60000]\nloss: 1.273360  [57664/60000]\nTest Error: \n Accuracy: 63.7%, Avg loss: 1.244470 \n\nEpoch 2\n-------------------------------\nloss: 1.250782  [   64/60000]\nloss: 1.358424  [ 6464/60000]\nloss: 1.121522  [12864/60000]\nloss: 1.036822  [19264/60000]\nloss: 1.188575  [25664/60000]\nloss: 1.127103  [32064/60000]\nloss: 1.138114  [38464/60000]\nloss: 1.059073  [44864/60000]\nloss: 1.033557  [51264/60000]\nloss: 1.098557  [57664/60000]\nTest Error: \n Accuracy: 65.0%, Avg loss: 1.083130 \n\nEpoch 3\n-------------------------------\nloss: 1.070835  [   64/60000]\nloss: 1.022191  [ 6464/60000]\nloss: 1.005594  [12864/60000]\nloss: 0.993012  [19264/60000]\nloss: 1.047417  [25664/60000]\nloss: 1.001495  [32064/60000]\nloss: 1.095251  [38464/60000]\nloss: 0.926997  [44864/60000]\nloss: 0.960782  [51264/60000]\nloss: 0.937367  [57664/60000]\nTest Error: \n Accuracy: 66.1%, Avg loss: 0.979457 \n\nEpoch 4\n-------------------------------\nloss: 0.900051  [   64/60000]\nloss: 1.099103  [ 6464/60000]\nloss: 1.052053  [12864/60000]\nloss: 0.843110  [19264/60000]\nloss: 0.914962  [25664/60000]\nloss: 1.017330  [32064/60000]\nloss: 0.707650  [38464/60000]\nloss: 0.890666  [44864/60000]\nloss: 1.078490  [51264/60000]\nloss: 0.758047  [57664/60000]\nTest Error: \n Accuracy: 67.3%, Avg loss: 0.909492 \n\nEpoch 5\n-------------------------------\nloss: 0.935071  [   64/60000]\nloss: 0.930360  [ 6464/60000]\nloss: 0.886458  [12864/60000]\nloss: 0.747989  [19264/60000]\nloss: 0.919060  [25664/60000]\nloss: 0.857149  [32064/60000]\nloss: 0.808115  [38464/60000]\nloss: 0.957309  [44864/60000]\nloss: 0.915866  [51264/60000]\nloss: 1.035016  [57664/60000]\nTest Error: \n Accuracy: 68.0%, Avg loss: 0.857042 \n\nEpoch 6\n-------------------------------\nloss: 0.711309  [   64/60000]\nloss: 0.731404  [ 6464/60000]\nloss: 0.778495  [12864/60000]\nloss: 0.826608  [19264/60000]\nloss: 0.690381  [25664/60000]\nloss: 0.793883  [32064/60000]\nloss: 1.049005  [38464/60000]\nloss: 0.860935  [44864/60000]\nloss: 0.850578  [51264/60000]\nloss: 0.894870  [57664/60000]\nTest Error: \n Accuracy: 69.2%, Avg loss: 0.820537 \n\nEpoch 7\n-------------------------------\nloss: 0.751307  [   64/60000]\nloss: 0.690765  [ 6464/60000]\nloss: 0.885832  [12864/60000]\nloss: 0.810388  [19264/60000]\nloss: 0.656271  [25664/60000]\nloss: 0.795354  [32064/60000]\nloss: 0.873639  [38464/60000]\nloss: 0.952544  [44864/60000]\nloss: 0.621379  [51264/60000]\nloss: 0.782824  [57664/60000]\nTest Error: \n Accuracy: 70.0%, Avg loss: 0.791091 \n\nEpoch 8\n-------------------------------\nloss: 0.706885  [   64/60000]\nloss: 0.791194  [ 6464/60000]\nloss: 0.665691  [12864/60000]\nloss: 0.586563  [19264/60000]\nloss: 0.746921  [25664/60000]\nloss: 0.670890  [32064/60000]\nloss: 0.818113  [38464/60000]\nloss: 0.725863  [44864/60000]\nloss: 0.793836  [51264/60000]\nloss: 0.689501  [57664/60000]\nTest Error: \n Accuracy: 71.0%, Avg loss: 0.764419 \n\nEpoch 9\n-------------------------------\nloss: 0.579552  [   64/60000]\nloss: 0.783948  [ 6464/60000]\nloss: 0.766569  [12864/60000]\nloss: 0.831361  [19264/60000]\nloss: 0.964704  [25664/60000]\nloss: 0.772870  [32064/60000]\nloss: 0.836838  [38464/60000]\nloss: 0.806005  [44864/60000]\nloss: 0.795276  [51264/60000]\nloss: 0.934505  [57664/60000]\nTest Error: \n Accuracy: 72.8%, Avg loss: 0.744880 \n\nEpoch 10\n-------------------------------\nloss: 0.493929  [   64/60000]\nloss: 0.790016  [ 6464/60000]\nloss: 0.750857  [12864/60000]\nloss: 0.762535  [19264/60000]\nloss: 0.822756  [25664/60000]\nloss: 0.723158  [32064/60000]\nloss: 0.535035  [38464/60000]\nloss: 0.708430  [44864/60000]\nloss: 0.695287  [51264/60000]\nloss: 0.616080  [57664/60000]\nTest Error: \n Accuracy: 73.5%, Avg loss: 0.724422 \n\nDone!"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html#further-reading",
    "href": "posts/100-days-of-pytorch/day-4-building-and-training-a-neural-network/index.html#further-reading",
    "title": "Day 4 - PyTorch Basics: Building and Training a Neural Network",
    "section": "Further reading",
    "text": "Further reading\n\ntorch.nn under the hood\ntorch.nn examples"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html",
    "href": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html",
    "title": "Day 2: PyTorch Basics - Dataset and DataLoader",
    "section": "",
    "text": "According to PyTorch:\n‚ÄúCode for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity.‚Äù\nIn short, we try to prevent messy notebooks and data leakage by seperating our data and data processing from our model. This is done with the Dataset and DataLoader classes."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#why-seperate-classes-anyway",
    "href": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#why-seperate-classes-anyway",
    "title": "Day 2: PyTorch Basics - Dataset and DataLoader",
    "section": "",
    "text": "According to PyTorch:\n‚ÄúCode for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity.‚Äù\nIn short, we try to prevent messy notebooks and data leakage by seperating our data and data processing from our model. This is done with the Dataset and DataLoader classes."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#how-to-use-the-pytorch-dataset-class",
    "href": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#how-to-use-the-pytorch-dataset-class",
    "title": "Day 2: PyTorch Basics - Dataset and DataLoader",
    "section": "How to use the PyTorch Dataset class?",
    "text": "How to use the PyTorch Dataset class?\nWe will see that working with these classes is pretty easy. PyTorch has commonly datasets built-in, ready to work with. Since the fashionMNIST dataset is used for computer vision-related tasks, it is stored in the torchvision module.\nThe fashionMNIST dataset takes 4 parameters:\n\nroot is the folder name where the data will be stored in.\ntrain specifies if you want to download the training or testing data.\ndownload downloads the data from the internet when you don‚Äôt have it locally yet.\ntransform takes a PIL image and transforms it to a tensor.\n\nLet‚Äôs import the fashionMNIST dataset.\n\n\nShow imports\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n\n\n\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor()\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor()\n)"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#dataset-attributes",
    "href": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#dataset-attributes",
    "title": "Day 2: PyTorch Basics - Dataset and DataLoader",
    "section": "Dataset attributes",
    "text": "Dataset attributes\nNow that we saved the fashionMNIST dataset in a Dataset object, what can we do with it?\n\n# Dataset summary \ntraining_data\n\n# Class labels\ntraining_data.classes\n\n# Select a row of data\nimg, label = training_data[0]\n\n\n\nShow output\n\n\n\ntraining_data:\nDataset FashionMNIST\n    Number of datapoints: 60000\n    Root location: data\n    Split: Train\n    StandardTransform\nTransform: ToTensor() \n\ntraining_data.classes:\n[\n  'T-shirt/top',\n  'Trouser',\n  'Pullover',\n  'Dress',\n  'Coat',\n  'Sandal',\n  'Shirt',\n  'Sneaker',\n  'Bag',\n  'Ankle boot',\n] \n\nlabel:\n9\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt‚Äôs always a good idea to inspect your data. Let‚Äôs look at img and label from the first row of data.\n\n\n\nplt.imshow(img.squeeze(), cmap='gray')\nplt.set_title(training_data.classes[label])\n\n\n\n\n\n\n\n\n\n\nThat indeed looks like an ankle boot, very nice!"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#using-your-own-data-with-dataset",
    "href": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#using-your-own-data-with-dataset",
    "title": "Day 2: PyTorch Basics - Dataset and DataLoader",
    "section": "Using your own data with Dataset",
    "text": "Using your own data with Dataset\nWe don‚Äôt always want to use predefined datasets. Very often we have our own data that we want to use. Pytorch has two ways of creating your own dataset. the map-style dataset, which is most commonly used, and the iterable-style dataset, for data that comes in on the fly, such as user-log data. The map-style behaves as you would likely expect from a dataset: you know its length beforehand, and you can select data through an index. For this, map-style datasets need to implement the __len__ and __getitem__ method. Let‚Äôs use our own data with a map-style Dataset.\nConsider the case where we have a csv file of image file names and the labels associated with them.\n\n\n\n\n\n\n\n\n\nItem Name\nLabel\n\n\n\n\n0\ntshirt1.jpg\n0\n\n\n1\ntshirt2.jpg\n0\n\n\n2\n...\n...\n\n\n3\nankleboot999.jpg\n9\n\n\n\n\n\n\n\nWe would define a custom dataset class as such:\n\nimport os\nimport pandas as pd\nfrom torchvision.io import read_image\n\nclass CustomImageDataSet(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform # optional\n        self.target_transform = target_transform # optional\n    \n    def __len__(self):\n        return len(self.img_labels)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n\n        img = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n\n        if self.transform:\n            img = self.transform(img)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return img, label\n\nThe code above is a bit involved, so let‚Äôs walk through it.\n\n__init__ stores values that we pass in variables, and reads the labels file annotations_file.\n__len__ specifies the size of the dataset by returning the amount of labels.\n\n__getitem__ creates a path to an image. For example, if img_dir='images' and idx=0, then img_path is images/tshirt1.jpg. It then reads the image using a predefined PyTorch function, and reads the label. If any transformations are specified they are applied.\nWe can now select images and labels from our dataset, much like we did earlier in @selecting-img-label"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#how-to-use-the-pytorch-dataloader-class",
    "href": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#how-to-use-the-pytorch-dataloader-class",
    "title": "Day 2: PyTorch Basics - Dataset and DataLoader",
    "section": "How to use the PyTorch DataLoader class",
    "text": "How to use the PyTorch DataLoader class\nIn the code above we only specified how to return a single (image, label) pair. In practice, we typically use lots of images and labels (called batches) for per training step. Additionally, we want to shuffle data (to prevent overfitting) and we want to speed up the process using multiprocessing. This is where the DataLoader class steps in. Let‚Äôs use the DataLoader to retrieve 64 images at once.\n\nfrom torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n\n# Get data for one simulated training step\ntrain_image_features, train_labels = next(iter(train_dataloader))\n\nRemember that these images are the data used for one training step. Let‚Äôs see the batch of images that our dataloader just sent us.\n\n\nShow visualization code\nfigure = plt.figure(figsize=(8, 8))\ncols, rows = 8, 8\n\nfor i in range(cols * rows):\n    idx = i\n    img = train_image_features[idx]\n\n    figure.add_subplot(rows, cols, i +1)\n    plt.imshow(img.squeeze(), cmap=\"gray\")\n    plt.title(training_data.classes[train_labels[idx]], pad=1, fontsize=10)\n    plt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\nThat‚Äôs a lot of images! By using DataLoader, we have an easy way to retrieve lots of images from our data at once."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#different-ways-to-shuffle",
    "href": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#different-ways-to-shuffle",
    "title": "Day 2: PyTorch Basics - Dataset and DataLoader",
    "section": "Different ways to shuffle",
    "text": "Different ways to shuffle\nWe can also control how data is shuffled (or in other words, the way that the random batch is sampled). We do this by setting the sampler parameter of the DataLoader. When doing this we have to set shuffle=False, since the shuffle parameter essentially sets the sampler parameter for us.\n\nimport numpy as np\nfrom torch.utils.data.sampler import SequentialSampler, SubsetRandomSampler\n\n# Returns images in order.\n# The first batch will have the first 32 images, the second batch will have image 33-64, etc.\ntrain_loader = DataLoader(training_data, batch_size=32, sampler=SequentialSampler(training_data))\n\n# Sample randomly, only including the images 50-100.\nindices = np.arange(50, 101)\ntrain_loader = DataLoader(training_data, batch_size=32, sampler=SubsetRandomSampler(indices))\n\nThese DataLoaders will select images in order of appearance in data, and randomly sample a subset of the data. Read about all the ways to sample in the PyTorch documentation.\nTo summarize: With Dataset and DataLoader, PyTorch makes it easy to manage data efficiently and flexibly. In future posts, we‚Äôll explore how these tools integrate into full training loops."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#further-reading",
    "href": "posts/100-days-of-pytorch/day-2-datasets-dataloaders/index.html#further-reading",
    "title": "Day 2: PyTorch Basics - Dataset and DataLoader",
    "section": "Further Reading",
    "text": "Further Reading\nPyTorch also offers ways to speed up sampling through multiprocessing and memory-pinning, which are both reasonably complicated and have some warnings attached to them, the latter being the reason that I did not include them in this post. If you are interested, or already know all about multiprocessing and GPU computations you can read about the topics here. Thanks for reading all the way to the end, I hope to see you on day 3!"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html",
    "href": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html",
    "title": "Day 5: PyTorch Basics - Saving and Loading Models",
    "section": "",
    "text": "This post is part of a series on deploying models, other posts include:"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#how-to-save-a-pytorch-model",
    "href": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#how-to-save-a-pytorch-model",
    "title": "Day 5: PyTorch Basics - Saving and Loading Models",
    "section": "How to Save a PyTorch Model?",
    "text": "How to Save a PyTorch Model?\nLet‚Äôs reuse our model training code from the previous blog post.\n\n\nShow code\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import ToTensor\n\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor()\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor()\n)\n\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n\nclass OurNeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Define neural net structure here, so we can store weights in them.\n        self.flatten = nn.Flatten()\n        self.linear_relu_chain = nn.Sequential(\n            nn.Linear(in_features=28*28, out_features=512),\n            nn.ReLU(),\n            nn.Linear(in_features=512, out_features=512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n    \n    def forward(self, input):\n        # Use neural net structure to pass input data through\n\n        input = self.flatten(input) # Shape: (28,28) -&gt; shape: (784)\n\n        predictions = self.linear_relu_chain(input) # Shape: (784) -&gt; shape: (512) -&gt; shape: (512) -&gt; shape: (10)\n        \n        return predictions\n\ndef train_loop(dataloader, model, loss_func, optimizer):\n    size = len(dataloader.dataset)\n    model.train() # Set model to training mode\n\n    # Update parameters each new batch\n    for batch, (images, labels) in enumerate(dataloader):\n        model_predictions = model(images)\n        loss = loss_func(model_predictions, labels)\n\n        # Compute gradient with backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        # Something to look at while model trains\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * batch_size + len(images)\n            print(f\"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]\")\n\n\ndef checking_loop(dataloader, model, loss_func):\n    size = len(dataloader.dataset)\n    number_of_batches = len(dataloader)\n    test_loss, correct_amount = 0, 0\n\n    model.eval() # Set model to check/test mode\n\n    with torch.no_grad(): # We don't need to update parameters anymore. This speeds up testing.\n\n        # This dataloader contains the test images\n        for images, labels in dataloader:\n            model_predictions = model(images)\n            \n            loss = loss_func(model_predictions, labels).item()\n            test_loss += loss\n\n            predicted_labels = nn.Softmax(dim=1)(model_predictions).argmax(1)\n            correct = predicted_labels == labels\n            # Turn every 'True' into a 1, and sum over them, converting the resulting tensor to a python integer\n            correct_amount += correct.type(torch.float).sum().item()\n\n    test_loss /= number_of_batches\n    correct_amount /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct_amount):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n\")\n\n\nmodel = OurNeuralNetwork().to(\"cpu\")\n\nlearning_rate = 1e-3\nbatch_size = 64\nepochs = 5\n\nloss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n\nTraining the model again:\n\nepochs = 10\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loop(train_dataloader, model, loss_function, optimizer)\n    checking_loop(test_dataloader, model, loss_function)\nprint(\"Done!\")\n\n\n\nShow output\n\n\n\n\nEpoch 1\n-------------------------------\nloss: 1.469673  [   64/60000]\nloss: 1.433510  [ 6464/60000]\nloss: 1.416146  [12864/60000]\nloss: 1.377274  [19264/60000]\nloss: 1.353796  [25664/60000]\nloss: 1.429164  [32064/60000]\nloss: 1.270087  [38464/60000]\nloss: 1.251621  [44864/60000]\nloss: 1.361366  [51264/60000]\nloss: 1.273360  [57664/60000]\nTest Error: \n Accuracy: 63.7%, Avg loss: 1.244470 \n\nEpoch 2\n-------------------------------\nloss: 1.250782  [   64/60000]\nloss: 1.358424  [ 6464/60000]\nloss: 1.121522  [12864/60000]\nloss: 1.036822  [19264/60000]\nloss: 1.188575  [25664/60000]\nloss: 1.127103  [32064/60000]\nloss: 1.138114  [38464/60000]\nloss: 1.059073  [44864/60000]\nloss: 1.033557  [51264/60000]\nloss: 1.098557  [57664/60000]\nTest Error: \n Accuracy: 65.0%, Avg loss: 1.083130 \n\nEpoch 3\n-------------------------------\nloss: 1.070835  [   64/60000]\nloss: 1.022191  [ 6464/60000]\nloss: 1.005594  [12864/60000]\nloss: 0.993012  [19264/60000]\nloss: 1.047417  [25664/60000]\nloss: 1.001495  [32064/60000]\nloss: 1.095251  [38464/60000]\nloss: 0.926997  [44864/60000]\nloss: 0.960782  [51264/60000]\nloss: 0.937367  [57664/60000]\nTest Error: \n Accuracy: 66.1%, Avg loss: 0.979457 \n\nEpoch 4\n-------------------------------\nloss: 0.900051  [   64/60000]\nloss: 1.099103  [ 6464/60000]\nloss: 1.052053  [12864/60000]\nloss: 0.843110  [19264/60000]\nloss: 0.914962  [25664/60000]\nloss: 1.017330  [32064/60000]\nloss: 0.707650  [38464/60000]\nloss: 0.890666  [44864/60000]\nloss: 1.078490  [51264/60000]\nloss: 0.758047  [57664/60000]\nTest Error: \n Accuracy: 67.3%, Avg loss: 0.909492 \n\nEpoch 5\n-------------------------------\nloss: 0.935071  [   64/60000]\nloss: 0.930360  [ 6464/60000]\nloss: 0.886458  [12864/60000]\nloss: 0.747989  [19264/60000]\nloss: 0.919060  [25664/60000]\nloss: 0.857149  [32064/60000]\nloss: 0.808115  [38464/60000]\nloss: 0.957309  [44864/60000]\nloss: 0.915866  [51264/60000]\nloss: 1.035016  [57664/60000]\nTest Error: \n Accuracy: 68.0%, Avg loss: 0.857042 \n\nEpoch 6\n-------------------------------\nloss: 0.711309  [   64/60000]\nloss: 0.731404  [ 6464/60000]\nloss: 0.778495  [12864/60000]\nloss: 0.826608  [19264/60000]\nloss: 0.690381  [25664/60000]\nloss: 0.793883  [32064/60000]\nloss: 1.049005  [38464/60000]\nloss: 0.860935  [44864/60000]\nloss: 0.850578  [51264/60000]\nloss: 0.894870  [57664/60000]\nTest Error: \n Accuracy: 69.2%, Avg loss: 0.820537 \n\nEpoch 7\n-------------------------------\nloss: 0.751307  [   64/60000]\nloss: 0.690765  [ 6464/60000]\nloss: 0.885832  [12864/60000]\nloss: 0.810388  [19264/60000]\nloss: 0.656271  [25664/60000]\nloss: 0.795354  [32064/60000]\nloss: 0.873639  [38464/60000]\nloss: 0.952544  [44864/60000]\nloss: 0.621379  [51264/60000]\nloss: 0.782824  [57664/60000]\nTest Error: \n Accuracy: 70.0%, Avg loss: 0.791091 \n\nEpoch 8\n-------------------------------\nloss: 0.706885  [   64/60000]\nloss: 0.791194  [ 6464/60000]\nloss: 0.665691  [12864/60000]\nloss: 0.586563  [19264/60000]\nloss: 0.746921  [25664/60000]\nloss: 0.670890  [32064/60000]\nloss: 0.818113  [38464/60000]\nloss: 0.725863  [44864/60000]\nloss: 0.793836  [51264/60000]\nloss: 0.689501  [57664/60000]\nTest Error: \n Accuracy: 71.0%, Avg loss: 0.764419 \n\nEpoch 9\n-------------------------------\nloss: 0.579552  [   64/60000]\nloss: 0.783948  [ 6464/60000]\nloss: 0.766569  [12864/60000]\nloss: 0.831361  [19264/60000]\nloss: 0.964704  [25664/60000]\nloss: 0.772870  [32064/60000]\nloss: 0.836838  [38464/60000]\nloss: 0.806005  [44864/60000]\nloss: 0.795276  [51264/60000]\nloss: 0.934505  [57664/60000]\nTest Error: \n Accuracy: 72.8%, Avg loss: 0.744880 \n\nEpoch 10\n-------------------------------\nloss: 0.493929  [   64/60000]\nloss: 0.790016  [ 6464/60000]\nloss: 0.750857  [12864/60000]\nloss: 0.762535  [19264/60000]\nloss: 0.822756  [25664/60000]\nloss: 0.723158  [32064/60000]\nloss: 0.535035  [38464/60000]\nloss: 0.708430  [44864/60000]\nloss: 0.695287  [51264/60000]\nloss: 0.616080  [57664/60000]\nTest Error: \n Accuracy: 73.5%, Avg loss: 0.724422 \n\nDone!\n\n\n\nThe learned weights are stored in an attribute called state_dict. We can save these weights to a file to reuse them later by calling torch.save() on the attribute.\n\ntorch.save(model.state_dict(), \"model_weights.pth\")"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#how-to-load-a-saved-model",
    "href": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#how-to-load-a-saved-model",
    "title": "Day 5: PyTorch Basics - Saving and Loading Models",
    "section": "How to Load a Saved Model?",
    "text": "How to Load a Saved Model?\nTo load the saved model, we first need to create a new instance of the same model class. Just the weights won‚Äôt do us any good, they need to correspond to the correct model structure. After instantiating a new model, we can copy the weights to it.\n\nweights = torch.load(\"model_weights.pth\", weights_only=True)\n\nmodel_from_weights = OurNeuralNetwork()\nmodel_from_weights.load_state_dict(weights)\nmodel_from_weights.eval()\n\n\n\nShow output\n\n\n\nOurNeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_chain): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n\n\n\nWe now have an exact copy of the neural network in a new variable!\nIf we want, we can inspect all the parameters (e.g to create visualizations that explain the model) through the models‚Äô state_dict()\n\nlayer_2_bias = model.state_dict()['linear_relu_chain.2.bias'] # We can access stored parameters through the state_dict keys\nprint(\"stored parameters in the form of 'layer_num.type': \", model.state_dict().keys(), '\\n')\nprint(\"Amount of values in the layer 2 bias:\", layer_2_bias.shape, '\\n') \nprint(\"First 10 biases in layer 2:\", layer_2_bias[:10])\n\n\n\nstored parameters in the form of 'layer_num.type': \n[\n    'linear_relu_chain.0.weight',\n    'linear_relu_chain.0.bias',\n    'linear_relu_chain.2.weight',\n    'linear_relu_chain.2.bias',\n    'linear_relu_chain.4.weight',\n    'linear_relu_chain.4.bias',\n]\nAmount of values in the layer 2 bias: torch.Size([512]) \n\nFirst 3 biases in layer 2: tensor([0.0234, 0.0045, 0.0241])"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#how-to-use-pre-trained-models",
    "href": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#how-to-use-pre-trained-models",
    "title": "Day 5: PyTorch Basics - Saving and Loading Models",
    "section": "How to Use Pre-Trained Models?",
    "text": "How to Use Pre-Trained Models?\nWe don‚Äôt have to train every model that we want to use ourselves. Lots of times, a better model trained on more data for longer is available freely online. PyTorch comes with pre-built model structures and weights for these models.\n\nfrom torchvision.models import resnet50, ResNet50_Weights\n\nweights = ResNet50_Weights.DEFAULT\nmodel = resnet50(weights)\n\nmodel.eval() \n\nWe can now use the ResNet50 model with best weights in our code."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#warmstarting-transfer-learning",
    "href": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#warmstarting-transfer-learning",
    "title": "Day 5: PyTorch Basics - Saving and Loading Models",
    "section": "Warmstarting / Transfer Learning",
    "text": "Warmstarting / Transfer Learning\nIn a scenario where we have a dataset with domain-specific images and we want to train an image recognition model on the data, we don‚Äôt have to start from scratch. We can define the model structure that we want and use imported weights for initializing the model training. This way the model does not have to learn what an image is again. Since that knowledge is already embedded in the downloaded weights, the model only needs to learn to recognize the domain-specific images. This PyTorch article explains how to do this."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#further-reading",
    "href": "posts/100-days-of-pytorch/day-5-save-and-load-model/index.html#further-reading",
    "title": "Day 5: PyTorch Basics - Saving and Loading Models",
    "section": "Further Reading",
    "text": "Further Reading\n\nSaving multiple models in one file"
  },
  {
    "objectID": "posts/backpropagation/index.html",
    "href": "posts/backpropagation/index.html",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "",
    "text": "A neural network consists of initially random weights and biases. Training the network boils down to minimizing a loss function that quantifies how wrong the network‚Äôs output is compared to the desired output. Gradient descent is the algorithm used for finding weights and biases that minimize the loss. The way these parameters are updated is determined by taking a step in the direction of the negative gradient of the loss function, which can be thought of as following an arrow that points towards where the loss function decreases the quickest. The problem is: how do we calculate this gradient?\nA first idea might be to grab a piece of paper and derive the gradient by hand. This is very tedious, requiring lots of matrix calculus and paper, and is infeasible for complex models. Additionally, this solution is not modular, since when you want to change something about the network or loss, you need to recalculate the gradient from scratch. We would like to implement an automatic way of calculating the gradient. Let‚Äôs look at some ways we could do this, excluding backpropagation for now.\n\nNumerical method: Adjust each parameter by a little and see how the loss changes in response. This method lacks precision and does not scale to large neural networks, where it would lead to lots of repeated computations, making it very slow.\nSymbolic method: The thought behind this method is that once an expression for the gradient is found, evaluating it can be fast. This method uses calculus rules to derive an exact expression for the gradient, but is even slower than the numerical method due to large, repeated expressions, making it infeasible to use in practice.\n\nThis is where backpropagation steps in. It brings exact precision while at the same time being extremely quick, making it the standard for updating parameters in neural networks."
  },
  {
    "objectID": "posts/backpropagation/index.html#why-backpropagation",
    "href": "posts/backpropagation/index.html#why-backpropagation",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "",
    "text": "A neural network consists of initially random weights and biases. Training the network boils down to minimizing a loss function that quantifies how wrong the network‚Äôs output is compared to the desired output. Gradient descent is the algorithm used for finding weights and biases that minimize the loss. The way these parameters are updated is determined by taking a step in the direction of the negative gradient of the loss function, which can be thought of as following an arrow that points towards where the loss function decreases the quickest. The problem is: how do we calculate this gradient?\nA first idea might be to grab a piece of paper and derive the gradient by hand. This is very tedious, requiring lots of matrix calculus and paper, and is infeasible for complex models. Additionally, this solution is not modular, since when you want to change something about the network or loss, you need to recalculate the gradient from scratch. We would like to implement an automatic way of calculating the gradient. Let‚Äôs look at some ways we could do this, excluding backpropagation for now.\n\nNumerical method: Adjust each parameter by a little and see how the loss changes in response. This method lacks precision and does not scale to large neural networks, where it would lead to lots of repeated computations, making it very slow.\nSymbolic method: The thought behind this method is that once an expression for the gradient is found, evaluating it can be fast. This method uses calculus rules to derive an exact expression for the gradient, but is even slower than the numerical method due to large, repeated expressions, making it infeasible to use in practice.\n\nThis is where backpropagation steps in. It brings exact precision while at the same time being extremely quick, making it the standard for updating parameters in neural networks."
  },
  {
    "objectID": "posts/backpropagation/index.html#the-computational-graph",
    "href": "posts/backpropagation/index.html#the-computational-graph",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "The computational graph",
    "text": "The computational graph\nLet‚Äôs see backpropagation in action through a simple example. Let‚Äôs say that we want to minimize the made-up loss function:\n\\[\nL(x, y, z) = (x + y)z\n\\]\nThe way a computer evaluates that function is by constructing a computational graph, consisting of several nodes and edges. It calculates the result by calculating the value at each node and passing it forward to the next node, until it reaches the end of the computation.\nBackpropagation uses this graph, storing intermediate computations that it will later need along the way. This is called the forward pass.\n\nLet‚Äôs name the nodes as follows:\n\\[\n\\begin{align}\n    q &= x + y \\\\\n    L &= zq\n\\end{align}\n\\]\nWe see that the derivatives are\n\\[\n\\frac{\\partial L}{\\partial z} = q,\n\\frac{\\partial L}{\\partial q} = z,\n\\frac{\\partial q}{\\partial x} = 1,\n\\frac{\\partial q}{\\partial y} = 1.\n\\]\nThese represent the effect that \\(z\\) and \\(q\\) have on \\(L\\), and the effect that \\(x\\) and \\(y\\) have on \\(q\\). However, we are not done yet! Remember that our goal was not to find these derivatives, but to find \\(\\frac{\\partial L}{\\partial x}, \\frac{\\partial L}{\\partial y}\\text{ } \\text{and } \\frac{\\partial L}{\\partial z}\\): the effect that \\(x\\), \\(y\\), and \\(z\\) have on the loss \\(L\\) at the end of the graph."
  },
  {
    "objectID": "posts/backpropagation/index.html#calculating-derivatives",
    "href": "posts/backpropagation/index.html#calculating-derivatives",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "Calculating derivatives",
    "text": "Calculating derivatives\nLooking at the graph, we see that when the input to \\(q\\) changes by \\(\\partial x\\), its output changes by \\(\\frac{\\partial q}{\\partial x}\\) as a result. How much \\(L\\) changes in response to a change in \\(q\\) is given by \\(\\frac{\\partial L}{\\partial q}\\). So the effect that a change in \\(x\\) has on \\(L\\), is given by chaining these effects together: \\(\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial q}\\frac{\\partial q}{\\partial x}\\).\nFollowing the same reasoning, we see that \\(\\frac{\\partial L}{\\partial y} = \\frac{\\partial L}{\\partial q}\\frac{\\partial q}{\\partial y}\\).\nSince \\(z\\) directly affects \\(L\\) without intermediate nodes, the change in \\(L\\) from a change in \\(z\\) is simply given by \\(\\frac{\\partial L}{\\partial z}\\)\nWe compute these values by moving from the end of the graph back to the beginning, this is called the backward pass.\nDuring the forward pass, every node received input from its upstream nodes, performed a basic computation, and then passed the result forward to its downstream nodes. When the final node in the graph computes its output, the computation is done. At that point the backward pass will start.\n\nNote: A downstream node is one that comes after the flow of data (i.e., closer to the output), and an upstream node is one that comes before (i.e., closer to the input). In the backward pass, since data flows from output to input, the terms are used in reverse."
  },
  {
    "objectID": "posts/backpropagation/index.html#propagating-backward",
    "href": "posts/backpropagation/index.html#propagating-backward",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "Propagating backward",
    "text": "Propagating backward\nLet‚Äôs zoom in on a random node during the backward pass.\n\n\n\nA node calculating how its inputs affect the loss, passing these values downstream.\n\n\nEventually, this node will receive a number from its output node, called the upstream gradient. This represents the change in the loss function all the way at the end of the graph when the output of this particular node changes. If the node receives multiple upstream gradients, it sums them up. After receiving the upstream gradient, the node computes local gradients, which represent how much each output of the node is affected by each input to the node. The node then calculates how each of its inputs affects the loss by multiplying each local gradient by the upstream gradient, and passes these downstream gradients to the respective input nodes. These input nodes then receive it as their own upstream gradient, repeating the process.\nThis entire process is a repeated application of the chain rule, which lets us compute how an input affects the final output through intermediate variables. When the process reaches the beginning of the graph, each input received an upstream gradient, meaning that we have the gradient of the loss function with respect to the inputs, and we are able to perform an iteration of gradient descent.\n\nTo summarize, a node:\n\nReceives an upstream gradient\nPasses along downstream gradients by multiplying the upstream gradient with local gradients.\n\nThe only thing left to do is to calculate these local gradients.\nWe do this by defining the local gradient for all node types we have in our graph beforehand.\nIn the case of an addition node, the local gradients are \\(1\\), so the downstream gradients are just the upstream gradient. For multiplication nodes, the local gradient with respect to an input node \\(a\\) is simply the product of all other input nodes. In a two-input case, this means that the gradient with respect to \\(a\\) is simply the other input. Other node types have simple gradient calculations as well!"
  },
  {
    "objectID": "posts/backpropagation/index.html#looking-back",
    "href": "posts/backpropagation/index.html#looking-back",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "Looking back",
    "text": "Looking back\nThinking about calculating the gradient in terms of this computational graph has melted away all our initial problems. Remember that calculating the gradient by hand is tedious or infeasible, but using backpropagation it has become trivial! Secondly, we no longer need to recalculate the gradient when we change the structure of the model. This is because the building blocks of the graph remain the same, so whilst the graph could have a different structure, the backpropagation algorithm remains the same, so our modularity issue is solved! Finally, backpropagation does not need to repeat calculations, making it extremely fast, and suitable for training deep neural networks.\nThank you for reading! I recommend that you check out Justin Johnson‚Äôs excellent video, which goes in-depth on generalizing to vector and tensor valued functions, and which this post was based upon."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-3-transforms/index.html",
    "href": "posts/100-days-of-pytorch/day-3-transforms/index.html",
    "title": "Day 3: Pytorch Basics - Transforms",
    "section": "",
    "text": "Data comes in many different formats. On the other hand, PyTorch can only do machine learning with one data type, the tensor. Transforms can convert any data to a tensor. In this post, we will look at how to transform images. I will assume that you are familiar with PyTorch Datasets. If you are not, I recommend reading this post before you continue."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-3-transforms/index.html#why-do-we-need-transform",
    "href": "posts/100-days-of-pytorch/day-3-transforms/index.html#why-do-we-need-transform",
    "title": "Day 3: Pytorch Basics - Transforms",
    "section": "",
    "text": "Data comes in many different formats. On the other hand, PyTorch can only do machine learning with one data type, the tensor. Transforms can convert any data to a tensor. In this post, we will look at how to transform images. I will assume that you are familiar with PyTorch Datasets. If you are not, I recommend reading this post before you continue."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-3-transforms/index.html#how-do-pytorch-transforms-work",
    "href": "posts/100-days-of-pytorch/day-3-transforms/index.html#how-do-pytorch-transforms-work",
    "title": "Day 3: Pytorch Basics - Transforms",
    "section": "How do PyTorch transforms work?",
    "text": "How do PyTorch transforms work?\nAll built-in datasets from the torchvision module take the parameters transform and target_tranform. They take in a function that transforms input data into a tensor, following predefined steps. To avoid having to write these functions ourselves, the torchvision.transforms module come with an image-to-tensor transform, called ToTensor out of the box.\nLet‚Äôs see an example through the FashionMNIST dataset.\n\nimport torch\nfrom torchvision.datasets import FashionMNIST\nfrom torchvision.transforms import ToTensor, Lambda\n\n\ndef our_own_transformation(target):\n    \"\"\"\n    Transformes target label to a one-hot tensor\n    example:\n\n    &gt;&gt;&gt; our_own_transformation(3)\n    &gt;&gt;&gt; torch.tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n    \"\"\"\n\n    zeros_list = torch.zeros(10, dtype=torch.float)\n    one_hot_index = torch.tensor(target)\n    one_hot_tensor = zeros_list.scatter_(0, one_hot_index, value=1)\n    return one_hot_tensor\n\nds_train = FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n    target_transform=Lambda(our_own_transformation)\n)\n\nds_test = FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n    target_transform=Lambda(our_own_transformation)\n)\n\nIn this code, we specified that we want to convert our training data to a tensor using the ToTensor method, and the target label to a tensor using our_own_transformation."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-3-transforms/index.html#further-reading",
    "href": "posts/100-days-of-pytorch/day-3-transforms/index.html#further-reading",
    "title": "Day 3: Pytorch Basics - Transforms",
    "section": "Further reading",
    "text": "Further reading\nThere are many more things we can do with transforms. We can rotate images, shift images, or we can chain transformations together to create a preprocessing pipeline. Since those usecases are too advanced for us at the moment, I will not cover them in this post. However, if you are curious or already more experienced, I recommend that you check out the example section on the Pytorch Website!"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html",
    "href": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html",
    "title": "Day 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX",
    "section": "",
    "text": "At the end of this tutorial, we will have a running deployment of an ONNX model on Hugging Face Spaces:"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#what-is-onnx",
    "href": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#what-is-onnx",
    "title": "Day 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX",
    "section": "What is ONNX?",
    "text": "What is ONNX?\nThere exist many different deep learning frameworks, across many different programming language. ONNX is a standard that defines a common set of building blocks and file format so that no matter what technology is used to train a model, when it is rendered to ONNX, it can be deployed virtually anywhere."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#converting-to-onnx",
    "href": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#converting-to-onnx",
    "title": "Day 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX",
    "section": "Converting to ONNX",
    "text": "Converting to ONNX\nIn this section I assume that you have a trained model called torch_model. If you don‚Äôt have one, or don‚Äôt know how to train your own model yet, this post explains how to build and train your own model.\nLet‚Äôs export our model to ONNX format. Since onnx.export runs the model, we need to supply an example input. Furthermore If we don‚Äôt want the batch size to be stationary, we need to set the dynamic_axes parameter.\n\nbatch_size = 1 # Random batch size\nexample_inputs = torch.rand((batch_size, 28, 28))\n\nonnx_program = torch.onnx.export(torch_model,\n                                 example_inputs,\n                                 input_names=['input'],\n                                 output_names=['output'],\n                                 dynamic_axes = { # variable input/output: first dimension, corresponding to batch size\n                                     'input' : {0 : 'batch_size'}, \n                                     'output' : {0 : 'batch_size'}\n                                     },\n                                 f=\"converted_model.onnx\",\n                                 export_params=True,\n                                 do_constant_folding=True # Optimization\n                                 )"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#running-the-onnx-model",
    "href": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#running-the-onnx-model",
    "title": "Day 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX",
    "section": "Running The ONNX Model",
    "text": "Running The ONNX Model\nWe can run any ONNX model inside python, using the onnxruntime package. Let‚Äôs run our own model that we just exported by downloading it from converted_model.onnx.\n\nimport onnx\n\nmodel = onnx.load(\"converted_model.onnx\")\nonnx.checker.check_model(model) # If this does not raise an error, we can continue\n\nSince ONNX does not support all data types that PyTorch uses, we need to do a bit of pre-processing before we can actually run the model.\n\nimport onnxruntime as ort\nimport numpy as np\n\n# Define a 'session', which will run the model\nort_session = ort.InferenceSession(\"converted_model.onnx\", providers=[\"CPUExecutionProvider\"])\n\n# The function that will convert PyTorch inputs to ONNX inputs\ndef to_numpy(tensor):\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n\n# Sample image \n\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=transforms.ToTensor()\n)\n\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n\nX, y = next(iter(train_dataloader))\ntesting_image = X[0]\ntesting_image_label = y[0]\n\ninput_name = ort_session.get_inputs()[0].name #  We specified this in our onnx_program's input_names parameter\ninput_values = to_numpy(testing_image)\nort_inputs = {input_name: input_values}\n\nort_outputs = ort_session.run(None, ort_inputs)\n\n\n\n\n\n\n\nTip\n\n\n\nI specified None for the output_names parameter of the .run() method. This computes all outputs. If we had specific outputs defined in onnx_program‚Äôs output_names, we could pass them here in a list. In this case, running .run(output_names=['output']) would result in the same output."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#sanity-checking-output",
    "href": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#sanity-checking-output",
    "title": "Day 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX",
    "section": "Sanity Checking Output",
    "text": "Sanity Checking Output\nUsing ONNX comes with the advantage of a standardized model format which we can run anywhere, but it still needs to give the same output as the model that we trained using PyTorch. Let‚Äôs make sure that nothing went wrong during conversion by comparing the PyTorch model output and the ONNX model output on the same input:\n\ntorch_outputs = torch_model(testing_image)\ntorch_outputs = to_numpy(torch_outputs)\n\nnp.testing.assert_allclose(ort_outputs[0], torch_outputs, rtol=1e-03, atol=1e-05) # No error: good to go!"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#how-to-get-onnx-predicted-labels",
    "href": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#how-to-get-onnx-predicted-labels",
    "title": "Day 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX",
    "section": "How To Get ONNX predicted labels?",
    "text": "How To Get ONNX predicted labels?\nWe can get the labels back by using np.argmax:\n\nidx_to_class = {\n    0: 'T-shirt/top',\n    1: 'Trouser',\n    2: 'Pullover',\n    3: 'Dress',\n    4: 'Coat',\n    5: 'Sandal',\n    6: 'Shirt',\n    7: 'Sneaker',\n    8: 'Bag',\n    9: 'Ankle boot'\n}\nlabel_index = np.argmax(ort_outputs[0], axis=1).item()\nclass_label = idx_to_class[label_index]\n\n\n\n\n\n\n\nTip\n\n\n\nWhen using a pre-trained model from torchvision.models, we can retrieve the class label through weights.meta[\"categories\"]. E.g ResNet50_Weights.meta[\"categories\"][label_index]"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#deploying-onnx-models",
    "href": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#deploying-onnx-models",
    "title": "Day 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX",
    "section": "Deploying ONNX models",
    "text": "Deploying ONNX models\nIn this section we will deploy our model to HuggingFace Spaces\nFor demonstration purposes I will be using a ResNet-50 with default weights, saved as a ‚Äò.onnx‚Äô file.\nFollow these steps to get started:\n\nCreate an account\nCreate an account at Hugging Face if you don‚Äôt have one.\nCreate a new space\nSelect ‚ÄòGradio‚Äô as the Space SDK. Gradio is a high-level API that generates a UI for machine learning models with very few code.\nGenerate a password for the Space\nGo to Settings &gt; Access tokens, and scroll down to ‚ÄòRepositories permissions‚Äô. Select your space and click the write permissions.\nPush the app\nWe only need to specify 2 functions to create a UI and do inference. The predict function, and a preprocessing function. The last depends on the model that you are using. PyTorch pre-trained models also have their required preprocessing made available through {weights_name.VERSION}.transforms():\n\n\n\nShow imports\nimport numpy as np\nimport onnxruntime as ort\nimport gradio as gr\nfrom PIL import Image\nfrom torchvision.models import ResNet50_Weights\n\n\n\nweights = ResNet50_Weights.DEFAULT\npreprocess = weights.transforms() # Necessary input transformations\nort_session = ort.InferenceSession(\"resnet50.onnx\", providers=[\"CPUExecutionProvider\"])\n\ndef preprocess_inputs(img: Image):\n    img = preprocess(img) # Change this line when using a different model\n    img_array = np.array(img).astype(np.float32)\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\ndef predict(img):\n    img = preprocess_inputs(img)\n    ort_inputs = {ort_session.get_inputs()[0].name: img}\n    ort_outputs = ort_session.run(None, ort_inputs)\n\n    label_index = np.argmax(ort_outputs[0], axis=1).item()\n    predicted_label = weights.meta[\"categories\"][label_index]\n    return predicted_label\n\nThat‚Äôs it! Now we can build the interface:\n\ndemo = gr.Interface(predict, gr.Image(type=\"pil\", image_mode=\"RGB\"), gr.Label())\ndemo.launch()\n\nYour file structure should look like this:\n\n\n.\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ app.py\n‚îú‚îÄ‚îÄ requirements.txt\n‚îî‚îÄ‚îÄ resnet50.onnx\n\n\nWhen all the code is in app.py and your project dependencies (imports) are listed in a requirements.txt you are ready to push and deploy. Run git push. If you encounter an error, you will need to install git-lfs"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#further-reading",
    "href": "posts/100-days-of-pytorch/day-6-deploying-model-to-huggingface-spaces-through-onnx/index.html#further-reading",
    "title": "Day 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX",
    "section": "Further Reading",
    "text": "Further Reading\n\nOfficial Gradio Quickstart"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html",
    "title": "Day 1: Pytorch Basics - Tensors",
    "section": "",
    "text": "If you are familiar with math, it might help to think about a tensor as an n-dimensional matrix. If you are not familiar with math, or just want a better explanation, you can think of a tensor as a collection of structured numbers that we can do quick math with. A tensor has two properties: shape, and dimension. Shape means how many numbers the tensor has along each axis. Dimension means the amount of axes that the tensor has. In the picture below, the dimension corresponds with the number of colored arrows, and the shape is denoted below the tensor.\n\n\n\nA vector (1D), a matrix (2D) and a 3 dimensional tensor (3D) are all tensors."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html#what-is-a-tensor",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html#what-is-a-tensor",
    "title": "Day 1: Pytorch Basics - Tensors",
    "section": "",
    "text": "If you are familiar with math, it might help to think about a tensor as an n-dimensional matrix. If you are not familiar with math, or just want a better explanation, you can think of a tensor as a collection of structured numbers that we can do quick math with. A tensor has two properties: shape, and dimension. Shape means how many numbers the tensor has along each axis. Dimension means the amount of axes that the tensor has. In the picture below, the dimension corresponds with the number of colored arrows, and the shape is denoted below the tensor.\n\n\n\nA vector (1D), a matrix (2D) and a 3 dimensional tensor (3D) are all tensors."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html#how-to-create-a-tensor",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html#how-to-create-a-tensor",
    "title": "Day 1: Pytorch Basics - Tensors",
    "section": "How to create a tensor?",
    "text": "How to create a tensor?\nFirst, import torch. After that we can create a tensor in two ways. From existing data, or with new data.\n\n# Create a tensor from existing data\ndata = [[1, 2], [3, 4]]\ntensor_from_data = torch.tensor(data)\nprint(tensor_from_data)\n\n# Create a tensor with new data\nones_tensor = torch.ones((2,2))\nprint(ones_tensor)\n\n\n\nShow output\n\n\n\ntensor([[1, 2],\n        [3, 4]])\ntensor([[1., 1.],\n        [1., 1.]])"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html#how-to-do-math-with-tensors",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html#how-to-do-math-with-tensors",
    "title": "Day 1: Pytorch Basics - Tensors",
    "section": "How to do math with tensors?",
    "text": "How to do math with tensors?\nThere are three ways to perform a math operation in PyTorch. Lets see an example with addition.\n\n\nInitialization code\n# Initialize tensors to do math with\nshape = (2,2)\ntensor1 = torch.rand(shape)\ntensor2 = torch.ones(shape)\n\n\n\n# 1. Python operators\ntensor1 + tensor2\n\n# 2. Built-in tensor method\ntensor1.add(tensor2)\n\n# 3. Output tensor\noutput_tensor = torch.zeros(shape)\ntorch.add(tensor1, tensor2, out=output_tensor)\n\n\n\n\n\n\n\nNote\n\n\n\nCurrently, I am not sure about the difference between these three methods. I imagine that in a situation where we need to choose between these, one of the three method will feel most natural to use."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html#some-built-in-tensor-methods",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html#some-built-in-tensor-methods",
    "title": "Day 1: Pytorch Basics - Tensors",
    "section": "Some built-in tensor methods",
    "text": "Some built-in tensor methods\nThere are over 1200 methods that we can perform on tensors. They can all be found at the PyTorch documentation. I skimmed through them and will give my beginner-opinion on which ones I believe will allow us to get a good start.\n\n\nMutating and indexing tensors\n\nKnowing how to select and change individual elements as well as groups of elements is an essential skill to have, and easily learned. Indexing tensors works a lot like python list and numpy array indexing.\n\ntensor = torch.rand((3, 3))\n\nfirst_row = tensor[0]\nfirst_two_row = tensor[:2]\nfirst_col = tensor[:, 0]\nfirst_two_col = tensor[:, :2]\n\n\n\nShow output\n\n\n\nEntire tensor:\ntensor([[0.4917, 0.5003, 0.4915],\n        [0.6349, 0.1063, 0.3295],\n        [0.0865, 0.7065, 0.6171]]) \n\nfirst row:\ntensor([0.4917, 0.5003, 0.4915]) \n\nfirst two rows:\ntensor([[0.4917, 0.5003, 0.4915],\n        [0.6349, 0.1063, 0.3295]]) \n\nfirst column:\ntensor([0.4917, 0.6349, 0.0865]) \n\nfirst two columns:\ntensor([[0.4917, 0.5003],\n        [0.6349, 0.1063],\n        [0.0865, 0.7065]])\n\n\n\nLets now look at how to combine multiple tensors.\n\ntensor_ones = torch.ones((3,3))\ntensor_ones[:, 0] = 4\n\n# Combine multiple tensors horizontally\nwide_combine = torch.cat((tensor, tensor_ones), dim=1)\neven_wider_combine = torch.cat((tensor, tensor_ones, tensor_ones), dim=1)\n\n# Combine multiple tensors vertically\nhigh_combine = torch.cat((tensor, tensor_ones), dim=0)\n\n\n\nShow output\n\n\n\nHorizontal combine:\ntensor([[0.4917, 0.5003, 0.4915, 4.0000, 1.0000, 1.0000],\n        [0.6349, 0.1063, 0.3295, 4.0000, 1.0000, 1.0000],\n        [0.0865, 0.7065, 0.6171, 4.0000, 1.0000, 1.0000]]) \n\nWe can combine any number of tensors we want:\ntensor([[0.4917, 0.5003, 0.4915, 4.0000, 1.0000, 1.0000, 4.0000, 1.0000, 1.0000],\n        [0.6349, 0.1063, 0.3295, 4.0000, 1.0000, 1.0000, 4.0000, 1.0000, 1.0000],\n        [0.0865, 0.7065, 0.6171, 4.0000, 1.0000, 1.0000, 4.0000, 1.0000, 1.0000]]) \n\nVertical combine\ntensor([[0.4917, 0.5003, 0.4915],\n        [0.6349, 0.1063, 0.3295],\n        [0.0865, 0.7065, 0.6171],\n        [4.0000, 1.0000, 1.0000],\n        [4.0000, 1.0000, 1.0000],\n        [4.0000, 1.0000, 1.0000]])\n\n\n\n\n\n\nComparing tensors\n\nJust like with the math operations, we have different notation options to choose from when comparing tensors.\n\ntensor1 = torch.zeros((2,2))\ntensor1[0][0] = 10\ntensor2 = torch.ones((2,2))\n\n# Check if two tensors are equal\ntorch.equal(tensor1, tensor2)\ntensor1 == tensor2\n\n# Check if one tensor is greater or equal to another tensor\ntorch.greater_equal(tensor1, tensor2)\ntorch.ge(tensor1, tensor2)\ntensor1 &gt;= tensor2\n\n\n\nShow output\n\n\n\nTensor 1 equals tensor 2:\ntensor([[False, False],\n        [False, False]]) \n\nTensor 1 &gt;= tensor 2:\ntensor([[ True, False],\n        [False, False]])\n\n\n\nOther comparison operators are implemented like the ones shown above in the way you probably expect. If you can‚Äôt find the one you‚Äôre looking for, there exists a list of all comparison operators on the PyTorch website.\n\n\n\nMore creation methods\n\nBeing able to instantiate a tensor with other values than ones and zeros is also possible.\n\n# Create a tensor filled with the number 3\nthrees = torch.full(size=(2,2), fill_value=3)\n\n# Create a tensor based on the shape of another\ntensor_with_shape = torch.rand((4, 3))\ntensor_zeros = torch.zeros_like(tensor_with_shape)\n\n\n\nShow output\n\n\n\nthrees:\ntensor([[3, 3],\n        [3, 3]]) \n\ntensor_with_shape:\ntensor([[0.9459, 0.3627, 0.1254],\n        [0.3131, 0.3433, 0.3845],\n        [0.2971, 0.2271, 0.8955],\n        [0.5679, 0.0303, 0.2326]]) \n\ntensor_zeros:\ntensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]])\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe way we created tensor_zeros based on the shape of another tensor using zeros_like can also be done to the other ways we learned how to create a tensor, just by suffixing the method with _like.\n\n\n\nRandom numbers\n\nshape = (3,3)\n# Set an optional seed for reproducibility\ntorch.manual_seed(1)\n\n# Random integers \nrand_int = torch.randint(10, shape)\nrand_int_lower_bound = torch.randint(8, 10, shape)\n\n# Tensor values drawn from a distribution\nnormal = torch.randn(shape)\n\nprobability_tensor = torch.empty(shape).uniform_(0, 1) # The '_' suffix modifies the variable in place\nbernoulli =torch.bernoulli(probability_tensor) # Pass a tensor with values of how likely a '1' is.\n\n# Shuffle numbers from 0 to n-1 \npermutation = torch.randperm(10)\n\n\n\nShow output\n\n\n\nrand_int):\ntensor([[5, 9, 4],\n        [8, 3, 3],\n        [1, 1, 9]]) \n\nrand_int_lower_bound:\ntensor([[8, 8, 9],\n        [8, 9, 9],\n        [8, 8, 9]]) \n\nnormal:\ntensor([[-1.1948,  0.0250, -0.7627],\n        [ 1.3969, -0.3245,  0.2879],\n        [ 1.0579,  0.9621,  0.3935]]) \n\nprobability_tensor: \n\ntensor([[0.7140, 0.2676, 0.9906],\n        [0.2885, 0.8750, 0.5059],\n        [0.2366, 0.7570, 0.2346]])\nbernoulli:\ntensor([[1., 0., 1.],\n        [1., 1., 0.],\n        [0., 0., 0.]]) \n\npermutation:\ntensor([1, 9, 3, 6, 8, 0, 5, 2, 7, 4]) \n\n\n\n\n\nThank you for reading! Note that these are just the basics. Now is your time to do some work yourself. Read the documentation, and try some basic operations. As a starter, this post did not cover the different linear algebra operations, even though they are very useful! You might also peek at the more technical GPU operations. See you on day 2!"
  },
  {
    "objectID": "100-days-of-pytorch.html",
    "href": "100-days-of-pytorch.html",
    "title": "100 Days Of PyTorch",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\nDay 6: PyTorch Basics - Deploying Model to HuggingFace Spaces With Gradio and ONNX\n\n\nDeploying your model might seem like a daunting task, and in some cases, it certainly is. But it is arguably one of the most import things to learn, since a model that never makes it out of your local machine is not useful to anybody. In this post we learn how to convert a trained model to the ONNX format, and deploy it permanently on HuggingFace for free with Gradio.\n\n\n\n\n\nMay 13, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 5: PyTorch Basics - Saving and Loading Models\n\n\nPreviously, we learned how to train a neural network model. But how do we actually make predictions with it? And how can we use open-source models that other people trained? In this post we learn how to store and load the weights that the model learned during training, and how to use open-source models and weights\n\n\n\n\n\nMay 12, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 4 - PyTorch Basics: Building and Training a Neural Network\n\n\nLearn how to use torch.nn to build the neural network structure, and how to train the model to recognize images, using a training and evaluation loop. It assumes you are already familiar with the theory behind neural networks (i.e loss functions, gradient descent).\n\n\n\n\n\nMay 11, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3: Pytorch Basics - Transforms\n\n\n\n\n\n\n\n\nMay 10, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2: PyTorch Basics - Dataset and DataLoader\n\n\nIn this post we learn about how to download datasets with PyTorch Datasets, and how to retrieve data from them for training an ML model while keeping data and model separate. We will see that working with these classes is pretty easy, and allows us to use all kinds of handy built-in methods.\n\n\n\n\n\nMay 9, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1: Pytorch Basics - Tensors\n\n\nTensors lie at the heart of PyTorch. If we want to be proficient in PyTorch, we need to know what we can do with the Tensor object. There are over 1200 possible operations to perform on tensors, but only a few are needed to get started with PyTorch. In this post we learn what a Tensor is and how to perform basic operations with them. Familiarity with python programming is assumed.\n\n\n\n\n\nMay 8, 2025\n\n\nLiam Groen\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Hi, I‚Äôm Liam, a student on a journey to understand the world through machine learning, coding, data science, and mathematics.\nThis blog is my digital lab notebook ‚Äî a place where I explain what I‚Äôm learning, work through complex topics, and share insights that might help others learning too.\nWhether you‚Äôre just starting out or deep into the field, I hope you find something useful here.\n\n\nWriting is thinking. By distilling ideas into blog posts, I‚Äôm aiming to:\n\nDeepen my understanding of technical topics.\nBuild a consistent habit of learning and reflection.\nCreate a public portfolio of work as I grow in this field.\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\n\nDeploying your model might seem like a daunting task, and in some cases, it certainly is. But it is arguably one of the most import things to learn, since a model that never‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreviously, we learned how to train a neural network model. But how do we actually make predictions with it? And how can we use open-source models that other people trained?‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLearn how to use torch.nn to build the neural network structure, and how to train the model to recognize images, using a training and evaluation loop. It assumes you are‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiam Groen\n\n\nMay 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nIn this post we learn about how to download datasets with PyTorch Datasets, and how to retrieve data from them for training an ML model while keeping data and model‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTensors lie at the heart of PyTorch. If we want to be proficient in PyTorch, we need to know what we can do with the Tensor object. There are over 1200 possible operations‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow backpropagation is used to compute gradients in neural networks, using computational graphs and the chain rule.\n\n\n\nLiam Groen\n\n\nApr 20, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#why-i-blog",
    "href": "index.html#why-i-blog",
    "title": "Home",
    "section": "",
    "text": "Writing is thinking. By distilling ideas into blog posts, I‚Äôm aiming to:\n\nDeepen my understanding of technical topics.\nBuild a consistent habit of learning and reflection.\nCreate a public portfolio of work as I grow in this field."
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Home",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\n\nDeploying your model might seem like a daunting task, and in some cases, it certainly is. But it is arguably one of the most import things to learn, since a model that never‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreviously, we learned how to train a neural network model. But how do we actually make predictions with it? And how can we use open-source models that other people trained?‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLearn how to use torch.nn to build the neural network structure, and how to train the model to recognize images, using a training and evaluation loop. It assumes you are‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiam Groen\n\n\nMay 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nIn this post we learn about how to download datasets with PyTorch Datasets, and how to retrieve data from them for training an ML model while keeping data and model‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTensors lie at the heart of PyTorch. If we want to be proficient in PyTorch, we need to know what we can do with the Tensor object. There are over 1200 possible operations‚Ä¶\n\n\n\nLiam Groen\n\n\nMay 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow backpropagation is used to compute gradients in neural networks, using computational graphs and the chain rule.\n\n\n\nLiam Groen\n\n\nApr 20, 2025\n\n\n\n\n\n\nNo matching items"
  }
]