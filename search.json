[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a Dutch student with a passion for learning. Machine learning is a topic that I’m interested in, but have only learned the basics of during my studies. That is why I am trying to deepen my knowledge in the subject by reading a lot of books. Currently I am reading the classic Pattern Recognition and Machine learning, along with following the PyTorch tutorials, commiting myself to learn something every day!"
  },
  {
    "objectID": "100-days-of-pytorch.html",
    "href": "100-days-of-pytorch.html",
    "title": "100 Days Of PyTorch",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\nPytorch Basics: Tensors\n\n\n\n100 Days Of PyTorch\n\n\n\nTensors lie at the heart of PyTorch. If we want to be proficient in PyTorch, we need to know what we can do with the Tensor object. There are over 1200 possible operations to perform on tensors, but only a few are needed to get started with PyTorch. In this post we learn what a Tensor is and how to perform basic operations with them. Familiarity with python programming is assumed.\n\n\n\n\n\nMay 8, 2025\n\n\nLiam Groen\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html",
    "title": "Pytorch Basics: Tensors",
    "section": "",
    "text": "If you are familiar with math, it might help to think about a tensor as an n-dimensional matrix. If you are not familiar with math, or just want a better explanation, you can think of a tensor as a collection of structured numbers that we can do quick math with. A tensor has two properties: shape, and dimension. Shape means how many numbers the tensor has along each axis. Dimension means the amount of axes that the tensor has. In the picture below, the dimension corresponds with the number of colored arrows, and the shape is denoted below the tensor.\n\n\n\nA vector (1D), a matrix (2D) and a 3 dimensional tensor (3D) are all tensors."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html#what-is-a-tensor",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html#what-is-a-tensor",
    "title": "Pytorch Basics: Tensors",
    "section": "",
    "text": "If you are familiar with math, it might help to think about a tensor as an n-dimensional matrix. If you are not familiar with math, or just want a better explanation, you can think of a tensor as a collection of structured numbers that we can do quick math with. A tensor has two properties: shape, and dimension. Shape means how many numbers the tensor has along each axis. Dimension means the amount of axes that the tensor has. In the picture below, the dimension corresponds with the number of colored arrows, and the shape is denoted below the tensor.\n\n\n\nA vector (1D), a matrix (2D) and a 3 dimensional tensor (3D) are all tensors."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html#how-to-create-a-tensor",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html#how-to-create-a-tensor",
    "title": "Pytorch Basics: Tensors",
    "section": "How to create a tensor?",
    "text": "How to create a tensor?\nFirst, import torch. After that we can create a tensor in two ways. From existing data, or with new data.\n\n# Create a tensor from existing data\ndata = [[1, 2], [3, 4]]\ntensor_from_data = torch.tensor(data)\nprint(tensor_from_data)\n\n# Create a tensor with new data\nones_tensor = torch.ones((2,2))\nprint(ones_tensor)\n\n\n\nShow output\n\n\n\ntensor([[1, 2],\n        [3, 4]])\ntensor([[1., 1.],\n        [1., 1.]])"
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html#how-to-do-math-with-tensors",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html#how-to-do-math-with-tensors",
    "title": "Pytorch Basics: Tensors",
    "section": "How to do math with tensors?",
    "text": "How to do math with tensors?\nThere are three ways to perform a math operation in PyTorch. Lets see an example with addition.\n\n\nInitialization code\n# Initialize tensors to do math with\nshape = (2,2)\ntensor1 = torch.rand(shape)\ntensor2 = torch.ones(shape)\n\n\n\n# 1. Python operators\ntensor1 + tensor2\n\n# 2. Built-in tensor method\ntensor1.add(tensor2)\n\n# 3. Output tensor\noutput_tensor = torch.zeros(shape)\ntorch.add(tensor1, tensor2, out=output_tensor)\n\n\n\n\n\n\n\nNote\n\n\n\nCurrently, I am not sure about the difference between these three methods. I imagine that in a situation where we need to choose between these, one of the three method will feel most natural to use."
  },
  {
    "objectID": "posts/100-days-of-pytorch/day-1-tensors/index.html#some-built-in-tensor-methods",
    "href": "posts/100-days-of-pytorch/day-1-tensors/index.html#some-built-in-tensor-methods",
    "title": "Pytorch Basics: Tensors",
    "section": "Some built-in tensor methods",
    "text": "Some built-in tensor methods\nThere are over 1200 methods that we can perform on tensors. They can all be found at the PyTorch documentation. I skimmed through them and will give my beginner-opinion on which ones I believe will allow us to get a good start.\n\n\nMutating and indexing tensors\n\nKnowing how to select and change individual elements as well as groups of elements is an essential skill to have, and easily learned. Indexing tensors works a lot like python list and numpy array indexing.\n\ntensor = torch.rand((3, 3))\n\nfirst_row = tensor[0]\nfirst_two_row = tensor[:2]\nfirst_col = tensor[:, 0]\nfirst_two_col = tensor[:, :2]\n\n\n\nShow output\n\n\n\nEntire tensor:\ntensor([[0.8942, 0.8148, 0.9423],\n        [0.9512, 0.4707, 0.2919],\n        [0.4433, 0.1706, 0.8242]]) \n\nfirst row:\ntensor([0.8942, 0.8148, 0.9423]) \n\nfirst two rows:\ntensor([[0.8942, 0.8148, 0.9423],\n        [0.9512, 0.4707, 0.2919]]) \n\nfirst column:\ntensor([0.8942, 0.9512, 0.4433]) \n\nfirst two columns:\ntensor([[0.8942, 0.8148],\n        [0.9512, 0.4707],\n        [0.4433, 0.1706]])\n\n\n\nLets now look at how to combine multiple tensors.\n\ntensor_ones = torch.ones((3,3))\ntensor_ones[:, 0] = 4\n\n# Combine multiple tensors horizontally\nwide_combine = torch.cat((tensor, tensor_ones), dim=1)\neven_wider_combine = torch.cat((tensor, tensor_ones, tensor_ones), dim=1)\n\n# Combine multiple tensors vertically\nhigh_combine = torch.cat((tensor, tensor_ones), dim=0)\n\n\n\nShow output\n\n\n\nHorizontal combine:\ntensor([[0.8942, 0.8148, 0.9423, 4.0000, 1.0000, 1.0000],\n        [0.9512, 0.4707, 0.2919, 4.0000, 1.0000, 1.0000],\n        [0.4433, 0.1706, 0.8242, 4.0000, 1.0000, 1.0000]]) \n\nWe can combine any number of tensors we want:\ntensor([[0.8942, 0.8148, 0.9423, 4.0000, 1.0000, 1.0000, 4.0000, 1.0000, 1.0000],\n        [0.9512, 0.4707, 0.2919, 4.0000, 1.0000, 1.0000, 4.0000, 1.0000, 1.0000],\n        [0.4433, 0.1706, 0.8242, 4.0000, 1.0000, 1.0000, 4.0000, 1.0000, 1.0000]]) \n\nVertical combine\ntensor([[0.8942, 0.8148, 0.9423],\n        [0.9512, 0.4707, 0.2919],\n        [0.4433, 0.1706, 0.8242],\n        [4.0000, 1.0000, 1.0000],\n        [4.0000, 1.0000, 1.0000],\n        [4.0000, 1.0000, 1.0000]])\n\n\n\n\n\n\nComparing tensors\n\nJust like with the math operations, we have different notation options to choose from when comparing tensors.\n\ntensor1 = torch.zeros((2,2))\ntensor1[0][0] = 10\ntensor2 = torch.ones((2,2))\n\n# Check if two tensors are equal\ntorch.equal(tensor1, tensor2)\ntensor1 == tensor2\n\n# Check if one tensor is greater or equal to another tensor\ntorch.greater_equal(tensor1, tensor2)\ntorch.ge(tensor1, tensor2)\ntensor1 &gt;= tensor2\n\n\n\nShow output\n\n\n\nTensor 1 equals tensor 2:\ntensor([[False, False],\n        [False, False]]) \n\nTensor 1 &gt;= tensor 2:\ntensor([[ True, False],\n        [False, False]])\n\n\n\nOther comparison operators are implemented like the ones shown above in the way you probably expect. If you can’t find the one you’re looking for, there exists a list of all comparison operators on the PyTorch website.\n\n\n\nMore creation methods\n\nBeing able to instantiate a tensor with other values than ones and zeros is also possible.\n\n# Create a tensor filled with the number 3\nthrees = torch.full(size=(2,2), fill_value=3)\n\n# Create a tensor based on the shape of another\ntensor_with_shape = torch.rand((4, 3))\ntensor_zeros = torch.zeros_like(tensor_with_shape)\n\n\n\nShow output\n\n\n\nthrees:\ntensor([[3, 3],\n        [3, 3]]) \n\ntensor_with_shape:\ntensor([[0.5788, 0.5643, 0.9288],\n        [0.8084, 0.8708, 0.4467],\n        [0.6463, 0.9904, 0.3890],\n        [0.2245, 0.4862, 0.8490]]) \n\ntensor_zeros:\ntensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]])\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe way we created tensor_zeros based on the shape of another tensor using zeros_like can also be done to the other ways we learned how to create a tensor, just by suffixing the method with _like.\n\n\n\nRandom numbers\n\nshape = (3,3)\n# Set an optional seed for reproducibility\ntorch.manual_seed(1)\n\n# Random integers \nrand_int = torch.randint(10, shape)\nrand_int_lower_bound = torch.randint(8, 10, shape)\n\n# Tensor values drawn from a distribution\nnormal = torch.randn(shape)\n\nprobability_tensor = torch.empty(shape).uniform_(0, 1) # The '_' suffix modifies the variable in place\nbernoulli =torch.bernoulli(probability_tensor) # Pass a tensor with values of how likely a '1' is.\n\n# Shuffle numbers from 0 to n-1 \npermutation = torch.randperm(10)\n\n\n\nShow output\n\n\n\nrand_int):\ntensor([[5, 9, 4],\n        [8, 3, 3],\n        [1, 1, 9]]) \n\nrand_int_lower_bound:\ntensor([[8, 8, 9],\n        [8, 9, 9],\n        [8, 8, 9]]) \n\nnormal:\ntensor([[-1.1948,  0.0250, -0.7627],\n        [ 1.3969, -0.3245,  0.2879],\n        [ 1.0579,  0.9621,  0.3935]]) \n\nprobability_tensor: \n\ntensor([[0.7140, 0.2676, 0.9906],\n        [0.2885, 0.8750, 0.5059],\n        [0.2366, 0.7570, 0.2346]])\nbernoulli:\ntensor([[1., 0., 1.],\n        [1., 1., 0.],\n        [0., 0., 0.]]) \n\npermutation:\ntensor([1, 9, 3, 6, 8, 0, 5, 2, 7, 4]) \n\n\n\n\n\nThank you for reading! Note that these are just the basics. Now is your time to do some work yourself. Read the documentation, and try some basic operations. As a starter, this post did not cover the different linear algebra operations, even though they are very useful! You might also peek at the more technical GPU operations. See you on day 2!"
  },
  {
    "objectID": "posts/backpropagation/index.html",
    "href": "posts/backpropagation/index.html",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "",
    "text": "A neural network consists of initially random weights and biases. Training the network boils down to minimizing a loss function that quantifies how wrong the network’s output is compared to the desired output. Gradient descent is the algorithm used for finding weights and biases that minimize the loss. The way these parameters are updated is determined by taking a step in the direction of the negative gradient of the loss function, which can be thought of as following an arrow that points towards where the loss function decreases the quickest. The problem is: how do we calculate this gradient?\nA first idea might be to grab a piece of paper and derive the gradient by hand. This is very tedious, requiring lots of matrix calculus and paper, and is infeasible for complex models. Additionally, this solution is not modular, since when you want to change something about the network or loss, you need to recalculate the gradient from scratch. We would like to implement an automatic way of calculating the gradient. Let’s look at some ways we could do this, excluding backpropagation for now.\n\nNumerical method: Adjust each parameter by a little and see how the loss changes in response. This method lacks precision and does not scale to large neural networks, where it would lead to lots of repeated computations, making it very slow.\nSymbolic method: The thought behind this method is that once an expression for the gradient is found, evaluating it can be fast. This method uses calculus rules to derive an exact expression for the gradient, but is even slower than the numerical method due to large, repeated expressions, making it infeasible to use in practice.\n\nThis is where backpropagation steps in. It brings exact precision while at the same time being extremely quick, making it the standard for updating parameters in neural networks."
  },
  {
    "objectID": "posts/backpropagation/index.html#why-backpropagation",
    "href": "posts/backpropagation/index.html#why-backpropagation",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "",
    "text": "A neural network consists of initially random weights and biases. Training the network boils down to minimizing a loss function that quantifies how wrong the network’s output is compared to the desired output. Gradient descent is the algorithm used for finding weights and biases that minimize the loss. The way these parameters are updated is determined by taking a step in the direction of the negative gradient of the loss function, which can be thought of as following an arrow that points towards where the loss function decreases the quickest. The problem is: how do we calculate this gradient?\nA first idea might be to grab a piece of paper and derive the gradient by hand. This is very tedious, requiring lots of matrix calculus and paper, and is infeasible for complex models. Additionally, this solution is not modular, since when you want to change something about the network or loss, you need to recalculate the gradient from scratch. We would like to implement an automatic way of calculating the gradient. Let’s look at some ways we could do this, excluding backpropagation for now.\n\nNumerical method: Adjust each parameter by a little and see how the loss changes in response. This method lacks precision and does not scale to large neural networks, where it would lead to lots of repeated computations, making it very slow.\nSymbolic method: The thought behind this method is that once an expression for the gradient is found, evaluating it can be fast. This method uses calculus rules to derive an exact expression for the gradient, but is even slower than the numerical method due to large, repeated expressions, making it infeasible to use in practice.\n\nThis is where backpropagation steps in. It brings exact precision while at the same time being extremely quick, making it the standard for updating parameters in neural networks."
  },
  {
    "objectID": "posts/backpropagation/index.html#the-computational-graph",
    "href": "posts/backpropagation/index.html#the-computational-graph",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "The computational graph",
    "text": "The computational graph\nLet’s see backpropagation in action through a simple example. Let’s say that we want to minimize the made-up loss function:\n\\[\nL(x, y, z) = (x + y)z\n\\]\nThe way a computer evaluates that function is by constructing a computational graph, consisting of several nodes and edges. It calculates the result by calculating the value at each node and passing it forward to the next node, until it reaches the end of the computation.\nBackpropagation uses this graph, storing intermediate computations that it will later need along the way. This is called the forward pass.\n\nLet’s name the nodes as follows:\n\\[\n\\begin{align}\n    q &= x + y \\\\\n    L &= zq\n\\end{align}\n\\]\nWe see that the derivatives are\n\\[\n\\frac{\\partial L}{\\partial z} = q,\n\\frac{\\partial L}{\\partial q} = z,\n\\frac{\\partial q}{\\partial x} = 1,\n\\frac{\\partial q}{\\partial y} = 1.\n\\]\nThese represent the effect that \\(z\\) and \\(q\\) have on \\(L\\), and the effect that \\(x\\) and \\(y\\) have on \\(q\\). However, we are not done yet! Remember that our goal was not to find these derivatives, but to find \\(\\frac{\\partial L}{\\partial x}, \\frac{\\partial L}{\\partial y}\\text{ } \\text{and } \\frac{\\partial L}{\\partial z}\\): the effect that \\(x\\), \\(y\\), and \\(z\\) have on the loss \\(L\\) at the end of the graph."
  },
  {
    "objectID": "posts/backpropagation/index.html#calculating-derivatives",
    "href": "posts/backpropagation/index.html#calculating-derivatives",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "Calculating derivatives",
    "text": "Calculating derivatives\nLooking at the graph, we see that when the input to \\(q\\) changes by \\(\\partial x\\), its output changes by \\(\\frac{\\partial q}{\\partial x}\\) as a result. How much \\(L\\) changes in response to a change in \\(q\\) is given by \\(\\frac{\\partial L}{\\partial q}\\). So the effect that a change in \\(x\\) has on \\(L\\), is given by chaining these effects together: \\(\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial q}\\frac{\\partial q}{\\partial x}\\).\nFollowing the same reasoning, we see that \\(\\frac{\\partial L}{\\partial y} = \\frac{\\partial L}{\\partial q}\\frac{\\partial q}{\\partial y}\\).\nSince \\(z\\) directly affects \\(L\\) without intermediate nodes, the change in \\(L\\) from a change in \\(z\\) is simply given by \\(\\frac{\\partial L}{\\partial z}\\)\nWe compute these values by moving from the end of the graph back to the beginning, this is called the backward pass.\nDuring the forward pass, every node received input from its upstream nodes, performed a basic computation, and then passed the result forward to its downstream nodes. When the final node in the graph computes its output, the computation is done. At that point the backward pass will start.\n\nNote: A downstream node is one that comes after the flow of data (i.e., closer to the output), and an upstream node is one that comes before (i.e., closer to the input). In the backward pass, since data flows from output to input, the terms are used in reverse."
  },
  {
    "objectID": "posts/backpropagation/index.html#propagating-backward",
    "href": "posts/backpropagation/index.html#propagating-backward",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "Propagating backward",
    "text": "Propagating backward\nLet’s zoom in on a random node during the backward pass.\n\n\n\nA node calculating how its inputs affect the loss, passing these values downstream.\n\n\nEventually, this node will receive a number from its output node, called the upstream gradient. This represents the change in the loss function all the way at the end of the graph when the output of this particular node changes. If the node receives multiple upstream gradients, it sums them up. After receiving the upstream gradient, the node computes local gradients, which represent how much each output of the node is affected by each input to the node. The node then calculates how each of its inputs affects the loss by multiplying each local gradient by the upstream gradient, and passes these downstream gradients to the respective input nodes. These input nodes then receive it as their own upstream gradient, repeating the process.\nThis entire process is a repeated application of the chain rule, which lets us compute how an input affects the final output through intermediate variables. When the process reaches the beginning of the graph, each input received an upstream gradient, meaning that we have the gradient of the loss function with respect to the inputs, and we are able to perform an iteration of gradient descent.\n\nTo summarize, a node:\n\nReceives an upstream gradient\nPasses along downstream gradients by multiplying the upstream gradient with local gradients.\n\nThe only thing left to do is to calculate these local gradients.\nWe do this by defining the local gradient for all node types we have in our graph beforehand.\nIn the case of an addition node, the local gradients are \\(1\\), so the downstream gradients are just the upstream gradient. For multiplication nodes, the local gradient with respect to an input node \\(a\\) is simply the product of all other input nodes. In a two-input case, this means that the gradient with respect to \\(a\\) is simply the other input. Other node types have simple gradient calculations as well!"
  },
  {
    "objectID": "posts/backpropagation/index.html#looking-back",
    "href": "posts/backpropagation/index.html#looking-back",
    "title": "Backpropagation: How Does Your Computer Calculate Gradients?",
    "section": "Looking back",
    "text": "Looking back\nThinking about calculating the gradient in terms of this computational graph has melted away all our initial problems. Remember that calculating the gradient by hand is tedious or infeasible, but using backpropagation it has become trivial! Secondly, we no longer need to recalculate the gradient when we change the structure of the model. This is because the building blocks of the graph remain the same, so whilst the graph could have a different structure, the backpropagation algorithm remains the same, so our modularity issue is solved! Finally, backpropagation does not need to repeat calculations, making it extremely fast, and suitable for training deep neural networks.\nThank you for reading! I recommend that you check out Justin Johnson’s excellent video, which goes in-depth on generalizing to vector and tensor valued functions, and which this post was based upon."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Why this blog?",
    "section": "",
    "text": "It is said that writing about a topic deepens your understanding of that topic, and there is a lot of writing involved with a blog. Additionally, this blog will serve as a good self-motivator to keep steadily learning about my interests. And who knows, maybe people will eventually end up reading it…\nThat being said, now it is time to dive into my self study and when I learn something new, I will post an update on here. In the meantime, look at this cool picture of the loss landscape of a neural network generated by Li et al., bye!\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\nPytorch Basics: Tensors\n\n\n\n100 Days Of PyTorch\n\n\n\nTensors lie at the heart of PyTorch. If we want to be proficient in PyTorch, we need to know what we can do with the Tensor object. There are over 1200 possible operations to perform on tensors, but only a few are needed to get started with PyTorch. In this post we learn what a Tensor is and how to perform basic operations with them. Familiarity with python programming is assumed.\n\n\n\n\n\nMay 8, 2025\n\n\nLiam Groen\n\n\n\n\n\n\n\n\n\n\n\n\nBackpropagation: How Does Your Computer Calculate Gradients?\n\n\n\nexplanation\n\n\n\nHow backpropagation is used to compute gradients in neural networks, using computational graphs and the chain rule.\n\n\n\n\n\nApr 20, 2025\n\n\nLiam Groen\n\n\n\n\n\nNo matching items"
  }
]